{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "011b2c9b-841e-4491-a0d3-8c52fc5db772",
   "metadata": {},
   "source": [
    "# Introduction : observer les traitements\n",
    "\n",
    "Vous connaissez Apache Spark comme le moteur de calcul distribu√© et puissant qui est largement utilis√© pour les traitements batch de donn√©es √† grande √©chelle. Cependant, comme tout autre outil de traitement de donn√©es de cette envergure, la performance de Spark peut √™tre grandement affect√©e par la fa√ßon dont vous configurez Spark, vous utilisez Spark et la fa√ßon dont vous g√©rez vos donn√©es au sein de Spark. Une configuration inad√©quate, un mauvais choix d'op√©rations ou un mauvais choix de cl√© dans vos datasets peuvent conduire √† des performances m√©diocres (par exemple, par sur-utilisation des disques et du r√©seau), voire √† des √©checs d'application (par exemple, en ramenant trop de donn√©es sur un n≈ìud Spark, provoquant ainsi un _out of memory error_ ou _OOM_).\n",
    "\n",
    "Cette formation a pour de comprendre les m√©canismes internes de Spark et d'apprendre √† percevoir dans vos applications les parties qui pourraient √™tre am√©lior√©es afin de gagner en temps de calcul.\n",
    "\n",
    "Dans ce notebook, nous allons commencer par mieux appr√©hender les outils de monitoring propos√©s par Spark (typiquement, Spark UI) et voir comment ces outils r√©agissent face √† des op√©rations Spark SQL simples. Nous allons donc particuli√®rement nous int√©resser aux plans d'ex√©cution issue de diff√©rents types de requ√™te."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f010a32-63ab-49ba-a06c-2f54c2096d7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pr√©lude\n",
    "\n",
    "Nous utilisons ici le moteur de notebook [Jupyter](https://jupyter.org/). Celui-ci a √©t√© d√©velopp√© en Python et fait partie des moteurs de notebook parmi les plus utilis√©s du moment (avec Databricks notebook, Zeppelin et Polynote).\n",
    "\n",
    "Jupyter se base sur des _kernels_ afin de faire fonctionner divers langages dans ses notebooks. Nous nous basons ici sur le _kernel_ [Almond](https://almond.sh/), qui utilise l'interpr√©teur Scala [Ammonite](https://ammonite.io/).\n",
    "\n",
    "üë∑ Ex√©cuter les deux cellules suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b374359-bdcc-4e36-85a5-08c6a7f82c27",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.slf4j:slf4j-reload4j:2.0.6`\n",
    "import $ivy.`org.apache.logging.log4j:log4j-api:2.8.2`\n",
    "import $ivy.`org.apache.logging.log4j:log4j-slf4j-impl:2.8.2`\n",
    "\n",
    "// Avoid disturbing logs\n",
    "import org.apache.log4j._\n",
    "import org.apache.log4j.varia._\n",
    "BasicConfigurator.configure(NullAppender.getNullAppender())\n",
    "\n",
    "import $ivy.`org.apache.spark::spark-core:3.4.1`\n",
    "import $ivy.`org.apache.spark::spark-sql:3.4.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402fae0-d848-4c0b-b0e0-97ad85c3c757",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .progress(enable = true, keep = true, useBars = false)\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"Spark tuning ‚Äì Introduction\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "val sparkContext = spark.sparkContext\n",
    "import $file.^.internal.spark_helper\n",
    "import spark_helper.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fc021-6dbb-4bc4-843f-c61358dca72e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Analyse d'un chargement de fichier CSV\n",
    "\n",
    "Nous allons commencer par charger un fichier CSV et observer ce qu'il se passe dans Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff16d73-9022-4de0-b5cf-ffcf4910df27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "val orders: DataFrame =\n",
    "  spark.read\n",
    "    .option(\"header\", true)\n",
    "    .csv(\"data/orders.csv\")\n",
    "\n",
    "orders.printSchema()\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a599a3f3-ea25-489b-880b-cba3fee516b7",
   "metadata": {},
   "source": [
    "üëÄ **Ce qu'il faut voir** üëÄ\n",
    "\n",
    "Avant de basculer sur Spark¬†UI, Spark (via Almond) fait appara√Ætre deux t√¢ches (done), avec un libell√© du style `csv at cell...` ou `showHTML`. Ces t√¢ches repr√©sentent en fait des jobs Spark.\n",
    "\n",
    "Ici, le premier job permet de r√©cup√©rer le nom des colonnes du contenu du fichier CSV. En effet, nous n'avons rien pr√©cis√© concernant la structure du fichier CSV √† part qu'il contient un en-t√™te. Spark doit donc r√©cup√©rer cet en-t√™te du fichier, afin de d√©terminer le nom des colonnes.\n",
    "\n",
    "Le second job est lanc√© par la commande `.showHTML` qui ajout√© sur la derni√®re ligne de la cellule par `%%data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad3d290-4fc2-4caf-bc4c-64f59592fde4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spark UI\n",
    "\n",
    "* Allez dans Spark UI (`http://<hostname>:4040`)\n",
    "* Cliquez sur l'onglet \"SQL\"\n",
    "\n",
    "√Ä ce niveau, vous allez voir 2 requ√™tes. La premi√®re (ID=0) est nomm√©e \"csv...\" et la seconde (ID=1) est nomm√©e \"show...\".\n",
    "    \n",
    "ü§î **Question** ü§î\n",
    "\n",
    " * Pour la requ√™te 0, combien de lignes ont √©t√© extraites du fichier `orders.csv` ? Expliquez ce nombre.\n",
    " * Pour la requ√™te 1, combien de lignes ont √©t√© extraites du fichier `orders.csv` ? Expliquez ce nombre.\n",
    "\n",
    "Note : le fichier contient environ 10¬†000 lignes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b2564-7210-4a3b-86bb-2c742d5cf3da",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plan d'ex√©cution\n",
    "    \n",
    "Dans Spark UI, affichez le d√©tail de la requ√™te 1. En bas, de la page, cliquez sur `> Details`.\n",
    "    \n",
    "Dans l'encadr√© \"Details\", vous voyez appara√Ætre les plans d'ex√©cution de votre requ√™te. 4 plans sont affich√©s :\n",
    "    \n",
    "* \"Parsed Logical Plan\" : c'est le plan d'ex√©cution qui est issue directement de votre requ√™te.\n",
    "* \"Analyzed Logical Plan\" : c'est √† nouveau le plan de votre requ√™te, mais avec la r√©solution des noms et des types.\n",
    "* \"Optimized Logical Plan\" : il s'agit d'une premi√®re optimisation de votre requ√™te, sans consid√©rer le support physique.\n",
    "* \"Physical Plan\" : il s'agit du plan qui sera effectivement ex√©cut√©. Il a √©t√© g√©n√©r√© apr√®s une seconde optimisation prenant en compte le support physique.\n",
    "    \n",
    "Chacun des plans se lisent du bas vers le haut : la premi√®re op√©ration du traitement se trouve en bas et la derni√®re op√©ration du traitement se trouve en haut.\n",
    "\n",
    "ü§î **Question** ü§î\n",
    "\n",
    "Dans le plan physique, au niveau de l'op√©ration,\n",
    "\n",
    "* Quel type d'op√©ration est lanc√©e en premier lieu ?\n",
    "* Remarquez la structure qui sera extraite de ce traitement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9ed4e8-4fb1-412b-b091-6effbaced898",
   "metadata": {},
   "source": [
    "### Explain\n",
    "\n",
    "Une fa√ßon de voir le plan d'ex√©cution, c'est d'utiliser la m√©thode `.explain()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33c4a9-ed82-4a9a-a579-35ad13aaf7f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b2518d-0762-40c3-b1ee-36317d1f25ce",
   "metadata": {},
   "source": [
    "Il est possible d'utiliser ces options sous forme de cha√Æne de caract√®res sur la m√©thode `.explain()`\n",
    "\n",
    "* simple affiche uniquement le plan physique.\n",
    "* extended: affiche le plan logique et le plan physique.\n",
    "* codegen: affiche le plan physique et le code g√©n√©r√© s'il est disponible.\n",
    "* cost: affiche le plan logique et les statistiques, si elles sont disponibles.\n",
    "* formatted: s√©pare la sortie en deux parties : une vue g√©n√©rale sur le plan physique et les d√©tails de chacun des n≈ìuds du plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8c601-365a-4bd3-8733-547d55b72753",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders.explain(\"formatted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec174c2-2578-4ccf-a099-fe8e3799e212",
   "metadata": {},
   "source": [
    "### Explain ou Spark UI pour le plan d'ex√©cution ?\n",
    "\n",
    "La m√©thode `.explain()` permet d'obtenir imm√©diatement dans un code diverses informations concernant une requ√™te, sans avoir √† rechercher l'URL de Spark UI. Cependant, `.explain()` a une limitation : `.explain()` vous fournira les informations qu'il pourra obtenir d'une requ√™te avant son ex√©cution. De fait, `.explain()` ne donnera pas le plan qui a √©t√© effectivement ex√©cut√©, en particulier, les temps interm√©diaires d'ex√©cution ou les derni√®res optimisations qui ont √©t√© apport√©es sur le plan physique, suite aux statistiques obtenues sur les donn√©es, ou les modifications li√©es au cache.\n",
    "\n",
    "De son c√¥t√©, Spark UI offre la possibilit√©, une fois la requ√™te ex√©cut√©e, de voir\n",
    "* une repr√©sentation graphique du plan d'ex√©cution (sous forme de DAG),\n",
    "* le plan physique optimis√©,\n",
    "* le rattachement √† des jobs Spark Core et les phases d'√©change de donn√©es,\n",
    "* l'ensemble des caches utilis√©s.\n",
    "\n",
    "Par contre, sur de la donn√©es volumineuse, il faut attendre que le traitement soit fait pour avoir le plan d'ex√©ction final avec les stats.\n",
    "\n",
    "Donc, `.explain()` est donc bien pour avoir rapidement une id√©e de ce que va faire une requ√™te. Spark UI est bien pour voir dans le d√©tail ce qu'il s'est r√©ellement pass√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b374cc-93fc-4bd1-a4c9-48de076e0bc3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Projection\n",
    "\n",
    "üë∑ Lancez la requ√™te ci-dessous, qui effectue une projection des donn√©es sur une colonne, en utilisant `.select()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b58314-418d-4cac-a128-f37dd847e4e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "orders\n",
    "  .select($\"product\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b234b0b-9bc6-4789-9463-bdb8b395cbec",
   "metadata": {},
   "source": [
    "ü§î **Question** ü§î\n",
    "\n",
    "Dans le plan d'ex√©cution associ√© √† la requ√™te ci-dessus,\n",
    "\n",
    "* Quelle structure de donn√©e est r√©cup√©r√©e ?\n",
    "* Est-elle diff√©rente de celle extraite par la requ√™te pr√©c√©dente ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffddbd6b-5d19-4f18-8ed7-0b18418d8960",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Filtre\n",
    "\n",
    "üë∑ Ex√©cutez la requ√™te ci-dessous, qui filtre les donn√©es avec `.where()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a9660-ffc9-42bf-b866-a98df176e0c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "orders\n",
    "  .where($\"product\" === \"expresso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e552c24b-73d7-42d4-a3ec-57b5bf143fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "ü§î **Question** ü§î\n",
    "\n",
    "Selon le plan physique de cette requ√™te,\n",
    "\n",
    "* Quel est le filtre qui est appliqu√© sur les donn√©es ?\n",
    "* Combien de fois ce filtre appara√Æt dans le plan physique ?\n",
    "\n",
    "### Pushed down filters\n",
    "\n",
    "Lors de la lecture du fichier, nous pouvons voir que le filtre est aussi appliqu√©. C'est ce qu'indique le champ `PushedFilters`. Cette fonctionnalit√© est appel√©e _pushed down filters_. Elle consiste √† appliquer les filtres que vous utilisez dans votre requ√™te (haut niveau) au niveau du support physique (niveau bas). Cette fonctionnalit√© est surtout int√©ressante pour des sources de donn√©es comme les formats orient√©s colonnes (Parquet, ORC) ou les connexions JDBC, etc. Toutes les sources permettant de filtrer nativement les donn√©es.\n",
    "\n",
    "### WholeStageCodeGen\n",
    "\n",
    "Si vous regardez le DAG de la requ√™te, vous voyez que l'op√©ration Filter est inclu dans un n≈ìud plus vaste, nomm√© `WholeStageCodegen`. Ce n≈ìud indique que l'op√©ration Filter a √©t√© convertie en code Java et qu'elle a √©t√© compil√©e au runtime avant d'√™tre ex√©cut√©e.\n",
    "\n",
    "Le `WholeStageCodegen` pr√©sente ces avantages :\n",
    "* Permettre de regrouper une s√©rie d'op√©rations en une seule par composition.\n",
    "* Utiliser implicitement les espaces m√©moires off-heap, qui ne subit pas l'intervention du GC et dont les acc√®s sont optimis√©s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c4093e-3cd9-4895-b01c-6436145adeb0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deux op√©rations en une\n",
    "\n",
    "üë∑ Ex√©cutez la cellule ci-dessous et allez voir comment est interpr√©t√©e cette requ√™te dans Spark UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba604312-301c-475d-bdf9-0a4e5e9274d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "orders\n",
    "  .where($\"product\" === \"expresso\")\n",
    "  .select($\"client\", $\"price\" * 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c557e-a940-4528-8775-3d3ec64640de",
   "metadata": {
    "tags": []
   },
   "source": [
    "ü§î **Question** ü§î\n",
    "\n",
    "Est-ce que Spark a regroup√© les 2 op√©rations de la requ√™te ci-dessus en un seul bloque ?\n",
    "\n",
    "### Afficher le code g√©n√©r√©\n",
    "\n",
    "Il est possible d'afficher le code g√©n√©r√© par Spark.\n",
    "\n",
    "üë∑ Ex√©cuter la cellule ci-dessous et allez voir au niveau de la ligne 71 dans le code g√©n√©r√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff7e160-83d6-4c23-88bf-558b8c00f084",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders\n",
    "  .where($\"product\" === \"expresso\")\n",
    "  .select($\"client\", $\"price\" * 2)\n",
    "  .explain(\"codegen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43632eb-75e6-490f-8f3d-77b14687ddea",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Agr√©gation\n",
    "\n",
    "Nous avons vu jusque-l√† des op√©rations lin√©aires (filter, select). Nous allons maintenant voir une op√©ration plus complexe : l'agr√©gation.\n",
    "\n",
    "L'agr√©gation consiste √† composer une collection de valeur afin d'obtenir une valeur r√©sultante unique. Typiquement, il peut s'agir de compter le nombre d'√©l√©ments dans cette collection, de faire la somme des valeurs contenues s'il s'agit de nombres, de calculer un prix total sur une commande, de d√©terminer le dernier √©v√©nement √† prendre en compte...\n",
    "\n",
    "Dans le cadre de Spark, la collection consid√©r√©e est un dataframe. Le probl√®me auquel nous faisons face avec Spark, c'est qu'un dataframe s'apparente √† une collection dont les √©l√©ments sont √©parpill√©s sur plusieurs machines, et donc executors. Pour effectuer une agr√©gation dans ce cas, il faut commencer par r√©aliser cette agr√©gation en local sur chaque executor, afin d'obtenir un r√©sultat interm√©diaire. Les diff√©rents r√©sultats interm√©diaires sont ensuite envoy√©s au driver qui terminera l'agr√©gation.\n",
    "\n",
    "üë∑ Nous allons voir ce que cela donne avec un simple `.count`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf180e4-07f5-4dd5-b262-3e12fee96dce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0301a3-e60c-4112-ad1c-502d286fd7ca",
   "metadata": {},
   "source": [
    "Sur une agr√©gation de ce type, le plan d'ex√©cution ne peut √™tre vu que dans Spark UI.\n",
    "\n",
    "Dans Spark UI, nous pouvons remarquer que le plan physique est divis√© en deux sous-plan :\n",
    "* \"Initial Plan\" : plan physique initialement calcul√© par Spark\n",
    "* \"Final Plan\" : il s'agit d'une r√©vision du plan physique initial, apr√®s avoir pris en compte le volume des donn√©es.\n",
    "\n",
    "Dans le plan physique, nous voyons appara√Ætre `AdaptiveSparkPlan isFinalPlan=true`. Ce qui signifie que lors de l'ex√©cution de la requ√™te, Spark a calcul√© d'apr√®s les volum√©tries √† traiter qu'une optimisation √©tait encore possible et qu'il l'a appliqu√©e. Il s'agit de la mise en pratique de la fonctionnalit√© _Adaptive Query Execution_ (ou AQE), qui est une nouveaut√© de Spark 3.\n",
    "\n",
    "Dans le plan physique, nous pouvons voir les op√©rations suivantes :\n",
    "* `HashAggregate` : indique qu'une agr√©gation de donn√©es est effectu√©e par rapport aux cl√©s indiqu√©es dans les param√®tres de l'op√©ration, dont un hash est calcul√©. Ici, nous pouvons observer qu'aucune cl√© n'est utilis√©e. Dans les param√®tres, nous pouvons observer aussi `partial_count(1)` pour la premi√®re agr√©gation (il s'agit d'une agr√©gation locale) et `count(1)` pour la seconde agr√©gation (il s'agit de l'agr√©gation finale).\n",
    "* `Exchange SinglePartition` : `Exchange` signifie que des donn√©es sont √©chang√©es entre plusieurs executors. `SinglePartition` indique que les donn√©es sont dans une seule partition. Il y a donc un √©change de donn√©es dans une seule partition. Autrement dit, l'op√©ration ne fait rien.\n",
    "* `ShuffleQueryStage` : il s'agit de la phase d'√©change proprement. Cette op√©ration est ajout√©e aussi par la fonctionnalit√© AQE afin de permettre de dissocier les op√©rations aval des autres op√©rations et de permettre √† Spark de changer de strat√©gie en fonction des volum√©tries observ√©es."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf295de-3611-4305-8122-e4c0dbd404fa",
   "metadata": {},
   "source": [
    "#### Association avec Spark Core\n",
    "\n",
    "üë∑ Dans le haut de la page Spark UI, montrant les d√©tails de la requ√™te, vous avez un champ indiquant les jobs associ√©s en succ√®s. Il y en a deux. Cliquez sur celui le plus √† droite.\n",
    "\n",
    "Dans la page qui vient de s'ouvrir, vous voyez appara√Ætre le DAG vu par Spark Core. Il est divis√© en deux parties. Chaque partie correspond √† un _stage_. Un _stage_ est une suite d'op√©ration Spark Core dans laquelle toutes les op√©rations se font en local dans l'executor. D√®s qu'on sort d'un stage pour entrer dans un autre, il y a un √©change de donn√©es qui s'effectue entre les executors.\n",
    "\n",
    "L'objectif est bien s√ªr d'avoir le moins de stage possible dans un traitement. En effet, un √©change de donn√©es signifie une utilisation du r√©seau et une baisse des performances.\n",
    "\n",
    "Dans le DAG affich√© dans Spark UI, nous pouvons voir que le stage de gauche est gris√© et annot√© _(skipped)_. C'est parce que le premier stage est en r√©alit√© effectu√© par le premier job de notre requ√™te.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d38ba7-50db-4c02-858a-4146d5f6e8b6",
   "metadata": {},
   "source": [
    "### Moyenne\n",
    "\n",
    "Voici une autre requ√™te effectuant une agr√©gation au moyen cette fois de `.groupBy()` et de `.agg()`.\n",
    "\n",
    "La particularit√© ici par rapport √† `.count`, c'est qu'√† travers la m√©thode `.groupBy()`, nous d√©terminons une cl√© pour regrouper les valeurs. Ceci signifie que les donn√©es vont √™tre redistribu√©es, afin que celles ayant la m√™me cl√© se retrouvent au niveau du m√™me executor. Une fois la redistribution faite, l'agr√©gation par cl√© peut se faire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7796b-568b-40bb-9bb0-e62f011ceec3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "\n",
    "orders\n",
    "  .groupBy($\"client\")\n",
    "  .agg(avg($\"price\") as \"avg_price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4169f-40a2-4856-b016-d4ddd1485d04",
   "metadata": {},
   "source": [
    "ü§î **Question** ü§î\n",
    "\n",
    "* Quelles diff√©rences voyez-vous avec le plan d'ex√©cution dans le cas du `.count` ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa07d22-a81f-487d-9b34-b19b752cd62c",
   "metadata": {},
   "source": [
    "## Jointure\n",
    "\n",
    "Nous allons ce que donne le plan d'ex√©cution dans le cadre d'une jointure.\n",
    "\n",
    "Pour cela, nous allons utiliser un fichier de correspondance entre les identifiants des clients et leur nom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d845b-4cd8-48a0-ad99-9a6e7b283c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "val mapping = spark.read.option(\"header\", true).csv(\"data/client-mapping.csv\")\n",
    "\n",
    "mapping.printSchema()\n",
    "mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93206a7f-057c-4969-b5e4-595f4b6a0559",
   "metadata": {},
   "source": [
    "Le code ci-dessous effectue une jointure entre nos deux dataframes.\n",
    "\n",
    "La jointure est une op√©ration particuli√®re qui implique de redistribuer sur le cluster les donn√©es, un peu comme pour l'agr√©gation. Mais pour la jointure, il existe divers strat√©gie que nous √©tudierons dans un prochain Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5c649-05b2-4585-964e-136db0fcf4d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "orders\n",
    "  .join(mapping, $\"client\" === $\"clientId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e7ff26-6cfb-4b82-b311-7b6528b26473",
   "metadata": {},
   "source": [
    "ü§î **Question** ü§î\n",
    "* Comment est repr√©sent√©e la jointure dans le graphe dans Spark UI ?\n",
    "\n",
    "La notion de _broadcast_ implique l'id√©e de partir d'une valeur et de la copier telle quelle au niveau de l'ensemble des ex√©cuteurs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c548c75-50bc-4b8d-9709-735a6bf0de66",
   "metadata": {},
   "source": [
    "## User-Defined Function (UDF)\n",
    "\n",
    "Nous allons voir maintenant l'effet d'une UDF sur le plan d'ex√©cution.\n",
    "\n",
    "üë∑ Ex√©cutez la cellule ci-dessous qui utilise les fonctions _builtins_ de Spark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f224d-0eb3-4297-81cc-1c0702702ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "val q1 = orders.withColumn(\"date\", to_date($\"timestamp\"))\n",
    "\n",
    "q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169a07cf-e160-48b8-8fd2-7424832a889c",
   "metadata": {},
   "source": [
    "üë∑ Ex√©cutez la cellule ci-dessous qui d√©finie et utilise une UDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f3775-848a-4af0-a326-2e3d432a1fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "def toDate(timestamp: java.sql.Timestamp): java.sql.Date = {\n",
    "  java.sql.Date.valueOf(timestamp.toLocalDateTime().toLocalDate())\n",
    "}\n",
    "\n",
    "val toDate_udf = udf(toDate(_)).withName(\"toDate_udf\")\n",
    "\n",
    "val q2 = orders.withColumn(\"date\", toDate_udf($\"timestamp\"))\n",
    "\n",
    "q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901f4bf5-aaec-41bd-92cc-8f5335db2ef0",
   "metadata": {},
   "source": [
    "ü§î **Question** ü§î\n",
    "\n",
    "Selon le plan d'ex√©cution de ces deux requ√™tes, quels diff√©rences apparaissent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1354df-b4ee-4ced-b119-081c223632e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q1.explain(\"formatted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8de20f8-27b0-43e8-afb5-6c526eeb66e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q2.explain(\"codegen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5796a1d1-9466-4e9f-ab3f-7000e3dc07a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
