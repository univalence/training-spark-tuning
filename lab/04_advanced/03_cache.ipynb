{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c306cbd7-f740-45f6-b531-f8dfa0da2b50",
   "metadata": {},
   "source": [
    "# Gestion du cache\n",
    "\n",
    "Le principe d'un cache est de conserver les r√©sultats de requ√™tes pour ne pas avoir √† les recalculer lorsque ces requ√™tes seront √† nouveau re√ßues. Le cache est int√©ressant √† partir du moment o√π des requ√™tes reviennent assez fr√©quemment, sachant qu'en contrepartie, la cache va consommer de la ressource m√©moire, disque et CPU. Il faut que cette consommation de ressources soit plus rentable que la consommation faite par le calcul qu'implique la requ√™te re√ßue, pour que le cache soit consid√©r√© comme une option int√©ressante.\n",
    "\n",
    "Spark propose une fonctionnalit√© de cache au niveau Spark Core sur les RDD et Spark SQL sur les dataframe et les dataset. Dans le cadre de Spark SQL, le cache devient int√©ressant d√®s qu'un dataframe est utilis√© dans plusieurs requ√™tes s√©par√©es. Dans cette situation, l'utilisation du cache pour un dataframe permet au niveau de chacune des requ√™tes qui utilisent ce dataframe de r√©√©valuer √† chaque fois les calculs qui ont conduit √† ce dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75390f1b-21bf-451e-80f5-1833495b1e0c",
   "metadata": {},
   "source": [
    "## Pr√©lude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225a9d5-a485-48cf-96e5-088892f57d63",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.slf4j:slf4j-reload4j:2.0.6`\n",
    "import $ivy.`org.apache.logging.log4j:log4j-api:2.8.2`\n",
    "import $ivy.`org.apache.logging.log4j:log4j-slf4j-impl:2.8.2`\n",
    "\n",
    "// Avoid disturbing logs\n",
    "import org.apache.log4j._\n",
    "import org.apache.log4j.varia._\n",
    "BasicConfigurator.configure(NullAppender.getNullAppender())\n",
    "\n",
    "import $ivy.`org.apache.spark::spark-core:3.4.1`\n",
    "import $ivy.`org.apache.spark::spark-sql:3.4.1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f83f4a0-45a1-43a5-864f-6b8316c45446",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.rdd._\n",
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.storage.StorageLevel\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .progress(enable = true, keep = true, useBars = false)\n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"Spark tuning ‚Äî Cache\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "val sparkContext = spark.sparkContext\n",
    "import $file.^.internal.spark_helper\n",
    "import spark_helper.implicits._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb7b20c-8f3b-4769-9c81-982911e38e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def callWithName[A](name: String)(f: => A): A = {\n",
    "  spark.sparkContext.setCallSite(name)\n",
    "  try f\n",
    "  finally spark.sparkContext.clearCallSite()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9113a84-bf24-4458-8afa-af6e2319b486",
   "metadata": {},
   "source": [
    "## Introduction sur le cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acd6703-9a8e-407d-be66-faaa68ba1444",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "val orders: DataFrame =\n",
    "  spark.read\n",
    "    .option(\"header\", true)\n",
    "    .csv(\"data/orders.csv\")\n",
    "    .repartition(4)\n",
    "\n",
    "orders.printSchema()\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a1109d-f2fd-4936-807c-57aad33b8fb3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sans cache\n",
    "\n",
    "Nous voulons effectuer des analyses sur la journ√©e du 1er f√©vrier 2023, sans utiliser de cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3fc4f-8b7d-48bc-8a8c-782603d873bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "val partOfOrders = orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-02-01\")))\n",
    "\n",
    "partOfOrders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb84b0a-5b3b-4ca2-8a37-0ba5efb0fae7",
   "metadata": {},
   "source": [
    "Nous r√©cup√©rons d'abord le chiffre d'affaires de la journ√©e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d907dc4d-5cae-46c7-acd4-0cc0d193721d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"show revenue - no cache\") {\n",
    "  partOfOrders\n",
    "    .agg(round(sum($\"price\"), 2) as \"total\")\n",
    "    .show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf5bd4-a426-4590-a08a-81aac76fdd88",
   "metadata": {},
   "source": [
    "Nous allons ensuite analyser la r√©partition du chiffre d'affaires de la journ√©e sur les diff√©rents produits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b47212-7e41-490f-8590-6a3a7c15d252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"show product revenue - no cache\") {\n",
    "  partOfOrders\n",
    "    .groupBy($\"product\")\n",
    "    .agg(sum($\"price\") as \"total\")\n",
    "    .where($\"total\" >= 15.0)\n",
    "    .orderBy($\"total\".desc)\n",
    "    .show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169db4e5-a9ce-45c5-a619-4cf8476cd161",
   "metadata": {},
   "source": [
    "Nous r√©cup√©rons enfin la r√©partition des ventes par client sur le caf√© noisette et le total des ventes de la journ√©e sur ce produit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944085fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"show noisette - no cache\") {\n",
    "  partOfOrders\n",
    "    .where($\"product\" === \"noisette\")\n",
    "    .cube($\"client\")\n",
    "    .agg(sum($\"price\") as \"total\")\n",
    "    .orderBy($\"client\".desc)\n",
    "    .show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057b3b7a-b3ac-41a7-8744-b14ab7d00405",
   "metadata": {},
   "source": [
    "üëÄ **Question** üëÄ\n",
    "\n",
    "Dans toutes ces requ√™tes, lorsque nous regardons le plan d'ex√©cution, nous voyons des DAG relativement √©quivalents. De plus chaque requ√™te se traduit par l'ex√©cution de 3 jobs. Nous le voyons dans ce notebook, au niveau des barres de progression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e38d9a9-2ca5-4d40-a33e-40b3244dac4d",
   "metadata": {},
   "source": [
    "### Avec cache\n",
    "\n",
    "Nous allons maintenant ex√©cuter les m√™mes requ√™tes. Mais cette fois, nous allons mettre en cache le dataframe filtr√© sur la journ√©e 1er f√©vrier 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55da6c9c-4a43-4415-be1f-78e661dde27a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10\n",
    "\n",
    "val partOfOrders = orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-02-01\"))).cache()\n",
    "\n",
    "partOfOrders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dcbca5-c329-4ded-940d-980377afceca",
   "metadata": {
    "tags": []
   },
   "source": [
    "üë∑ Ex√©cutez les requ√™tes ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9273c87-89d4-40f7-811c-71b8a6ed6ae7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"show revenue - cache\") {\n",
    "  partOfOrders\n",
    "    .agg(round(sum($\"price\"), 2) as \"total\")\n",
    "    .show()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503bf02-6547-4da5-ad1c-6d43dd21b68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"show product revenue - cache\") {\n",
    "  partOfOrders\n",
    "    .groupBy($\"product\")\n",
    "    .agg(sum($\"price\") as \"total\")\n",
    "    .where($\"total\" >= 15.0)\n",
    "    .orderBy($\"total\".desc)\n",
    "    .show()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1fc4667-8b17-4a3c-8b61-7dedf9f1aed7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"show noisette - cache\") {\n",
    "  partOfOrders\n",
    "    .where($\"product\" === \"noisette\")\n",
    "    .cube($\"client\")\n",
    "    .agg(sum($\"price\") as \"total\")\n",
    "    .orderBy($\"client\".desc)\n",
    "    .show()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b160e7-5e17-4af8-bce1-6f92a6f3465a",
   "metadata": {},
   "source": [
    "üëÄ **Ce qu'il faut voir** üëÄ\n",
    "\n",
    "La diff√©rence, qui appara√Æt ici, est que l'ex√©cution des requ√™tes d'analyse n√©cessite cette 2 jobs au lieu de 3. Ce qui permet un gain en performance sur l'ex√©cution de ces requ√™tes.\n",
    "\n",
    "En regardant de plus pr√®s le plan d'ex√©cution de ces requ√™tes, nous remarquons que celui-ci est un plus grand. Dans le cadre de la mise en cache, Spark a ajout√© les √©tapes :\n",
    "\n",
    "* **InMemoryRelation** : mise en cache des donn√©es du dataframe\n",
    "* **InMemoryTableScan** : parcours des donn√©es du dataframe depuis le cache\n",
    "\n",
    "Ces √©tapes proviennent de `partOfOrders`.\n",
    "\n",
    "=> üë∑ Ex√©cutez la cellule suivante pour voir le plan d'ex√©cution li√© √† `partOfOrders`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521c5c60-53ee-4152-afe6-ba9ea2f202ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partOfOrders.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8912a685-ffd9-43df-8e2b-f1a60e55d624",
   "metadata": {},
   "source": [
    "En fait, dans les requ√™tes d'analyse, toutes les √©tapes pr√©c√©dentes _InMemoryTableScan_ ne sont pas ex√©cut√©es.\n",
    "\n",
    "Si vous allez dans Spark UI, dans l'onglet _Storage_ vous allez trouver un tableau avec une seule entr√©e, contenant les informations ci-dessous :\n",
    "\n",
    "* Storage Level: Disk Memory Deserialized 1x Replicated\n",
    "* Cached Partitions: 4\n",
    "* Fraction Cached: 100%\n",
    "* Size in Memory: 8.6 KiB\n",
    "* Size on Disk: 0.0 B\n",
    "\n",
    "Cette ligne unique indique les informations sur les donn√©es en cache li√©es √† `partOfOrders`.\n",
    "\n",
    "_Storage Level_ indique le type de stockage utilis√©. Ici, nous avons un stockage en m√©moire d√©s√©rialis√© (il s'agit uniquement d'objets Java stock√©s dans la _heap_ de la JVM) et sur disque, avec un unique r√©pliqua (il n'y a pas de r√©plication sur d'autres executor).\n",
    "\n",
    "Nous avons aussi la quantit√© de m√©moire utilis√©e et la quantit√© de donn√©es stock√©e sur disque.\n",
    "\n",
    "Si vous cliquez sur la ligne du tableau dans Spark UI, vous obtenez plus d'informations sur nos donn√©es en cache. Nous avons notamment la r√©partition des donn√©es en cache par partition avec les executor associ√©s. Et nous avons aussi la m√©moire restante pour le cache.\n",
    "\n",
    "Il est possible de supprimer le cache √† la main en utilisant la m√©thode `.unpersist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f0af4-fd6c-4ec7-b7ad-08bc0c31b66b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "partOfOrders.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3506677-751b-4279-91e2-2e10792e0149",
   "metadata": {},
   "source": [
    "Si vous retournez dans l'onglet _Storage_ de Spark UI, vous verrez que le tableau aura disparu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f99d29-5a6b-4c5a-a463-89bd850cb242",
   "metadata": {},
   "source": [
    "### Fonctionnement\n",
    "\n",
    "Le cache Spark SQL est un cache LRU (_Least Recently Used_). Ainsi, lorsque l'espace pour le cache manque, toutes les entr√©es les moins utilis√©es sont retir√©es du cache pour laisser de la place. Lors du prochain acc√®s aux donn√©es retir√©es, Spark recalculera ces donn√©es pour les r√©int√©grer dans le cache, en ayant au pr√©alable retir√© les donn√©es les moins utilis√©es, si le cache est √† nouveau plein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19b8692-88c5-49ce-9b7a-3465d82bd037",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Les diff√©rents niveaux de cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c17a2e-f4d2-426b-8052-861bbda1a87a",
   "metadata": {},
   "source": [
    "### CacheManager\n",
    "\n",
    "Spark SQL b√©n√©ficie d'un CacheManager qui centralise la gestion des caches.\n",
    "\n",
    "Il est possible de vider compl√®tement le cache √† travers son interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7890e15f-d69c-4714-8626-f7ec73dd7fea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val cacheManager = spark.sharedState.cacheManager\n",
    "\n",
    "cacheManager.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84718cc1-c518-4ee3-91a0-a09328dd6c43",
   "metadata": {},
   "source": [
    "Voyons le fonctionnement du CacheManager. Pour cela, nous allons mettre en cache 2 requ√™tes identiques, mais r√©clamant une strat√©gie du stockage du cache diff√©rente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf49b4c-347c-48c7-a89a-6a06a7a99bd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val orders_default: DataFrame =\n",
    "  spark.read.option(\"header\", true).csv(\"data/orders.csv\").repartition(4).cache()\n",
    "orders_default.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75402a40-2a5f-4d74-955f-0dcb49b12e37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val orders_memory: DataFrame =\n",
    "  spark.read.option(\"header\", true).csv(\"data/orders.csv\").repartition(4).persist(StorageLevel.MEMORY_ONLY)\n",
    "orders_default.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3109411-0fb6-4bbd-8fc2-a87d73b0f0db",
   "metadata": {},
   "source": [
    "üëÄ **Ce qu'il faut voir** üëÄ\n",
    "\n",
    "Si nous regardons dans Spark UI, bien que nous ayons produits deux dataframe, nous ne verrons qu'un seul cache dans l'onglet _Storage_.\n",
    "\n",
    "Plus exactement, la recherche du cache se fait selon l'op√©ration suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f517e9-790b-408d-8549-8a885703ca48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders_default.queryExecution.logical\n",
    "  .sameResult(\n",
    "    orders_memory.queryExecution.logical\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c85ff4-5f8a-4908-ad39-0e8e565ad362",
   "metadata": {},
   "source": [
    "Ce qui veut dire que ce qui est retenu, c'est plus exactement la similarit√© des r√©sultats obtenus par les dataframes et non pas sur l'√©galit√© entre les plans d'ex√©cution des dataframes.\n",
    "\n",
    "La difficult√© est que tout ceci est d√©termin√© avant l'ex√©cution de la requ√™te. Il est dans ce cas parfois difficile de d√©terminer si deux plans d'ex√©cution produiront des r√©sultats √©quivalents. Spark ne sait pas toujours le d√©terminer. Par contre, Spark va capable de d√©terminer si deux plans d'ex√©cution vont donner des r√©sultats diff√©rents.\n",
    "\n",
    "Pour retrouver des donn√©es en cache, Spark SQL passe par la m√©thode `.lookupCachedData()` du CacheManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd00245-367d-4b7c-a16b-7d2479797e2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "object test_unique_cache {\n",
    "  val cache_orders_default = cacheManager.lookupCachedData(orders_default).get\n",
    "  val cache_orders_memory = cacheManager.lookupCachedData(orders_memory).get\n",
    "\n",
    "  def run() = {\n",
    "    println(\"cache_orders_default.plan sameResult cache_orders_memory.plan: \" + cache_orders_default.plan.sameResult(cache_orders_memory.plan))\n",
    "    println(\"cache_orders_default: \" + cache_orders_default.cachedRepresentation.cacheBuilder.storageLevel)\n",
    "    println(\"cache_orders_memory: \" + cache_orders_memory.cachedRepresentation.cacheBuilder.storageLevel)\n",
    "  }\n",
    "}\n",
    "\n",
    "test_unique_cache.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d887edf-9707-48d8-a5dd-dd45fe3e89be",
   "metadata": {},
   "source": [
    "D'ailleurs, notre dataframe d'origine est lui aussi index√© dans le cache, m√™me si son plan d'ex√©cution d√©duit n'a pas chang√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a571729f-14a2-4838-9a5e-8c116448cd3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "orders.explain()\n",
    "cacheManager.lookupCachedData(orders).isDefined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c5af9-b077-423a-9107-f7386fc735b4",
   "metadata": {},
   "source": [
    "Si vous ex√©cutez la cellule ci-dessous et que vous allez dans Spark UI, vous verrez appara√Ætre une √©tape InMemoryRelation et InMemoryTableScan, indiquant que les donn√©es pour cette requ√™te n'ont pas √©t√© r√©cup√©r√©es depuis le fichier, mais depuis le cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9b89b9-18cb-462c-be7f-cb2710d6f966",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"take from order - before clear cache\") {\n",
    "  orders.take(1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4deee-ec83-4059-8878-d53ab8a0e2d0",
   "metadata": {},
   "source": [
    "Par contre, si nous vidons le cache, la r√©cup√©ration des donn√©es se fait depuis le fichier directement. Dans le plan d'ex√©cution, dans Spark UI, les √©tapes InMemoryRelation et InMemoryTableScan auront disparues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10d59c-7f2c-4f74-a62c-c2c2f277f9dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cacheManager.clearCache()\n",
    "\n",
    "orders.explain()\n",
    "cacheManager.lookupCachedData(orders).isDefined\n",
    "\n",
    "callWithName(\"take from order - after clear cache\") {\n",
    "  orders.take(1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad552ac-2d65-4e81-b5e3-62d5812195a9",
   "metadata": {},
   "source": [
    "### Stockage des caches\n",
    "\n",
    "Voici la liste des strat√©gies de stockage propos√©e par Spark.\n",
    "\n",
    "* **NONE** : pas de persistance (emp√™che le CacheManager de persister par la suite un type de requ√™te)\n",
    "* **DISK_ONLY** : persistance sur le disque local\n",
    "* **DISK_ONLY_2** : persistance sur disque r√©pliqu√©e sur 2 n≈ìuds\n",
    "* **DISK_ONLY_3** : persistance sur disque r√©pliqu√©e sur 3 n≈ìuds\n",
    "* **MEMORY_ONLY** : persistance en m√©moire\n",
    "* **MEMORY_ONLY_2** : persistance en m√©moire sur 2 n≈ìuds\n",
    "* **MEMORY_ONLY_SER** : persistance s√©rialis√©e en m√©moire\n",
    "* **MEMORY_ONLY_SER_2** : persistance s√©rialis√©e en m√©moire sur 2 n≈ìuds\n",
    "* **MEMORY_AND_DISK** : persistance en m√©moire et sur disque\n",
    "* **MEMORY_AND_DISK_2** : persistance en m√©moire et sur disque r√©pliqu√©e sur 2 n≈ìuds\n",
    "* **MEMORY_AND_DISK_SER** : persistance s√©rialis√©e en m√©moire et sur disque\n",
    "* **MEMORY_AND_DISK_SER_2** : persistance s√©rialis√©e en m√©moire et sur disque r√©pliqu√©e sur 2 n≈ìuds\n",
    "* **OFF_HEAP** : persistance en m√©moire _off heap_ (_exp√©riemntal_)\n",
    "\n",
    "La s√©rialisation propos√©e ici utilise un encodage binaire propre √† Spark et qui reconnu comme efficace. Il permet de gagner de l'espace en m√©moire, en demandant un effort suppl√©mentaire sur le CPU.\n",
    "\n",
    "Le stockage sur disque est bien √©videmment plus co√ªteux que le stockage en m√©moire. Il faut dans ce cas que le recalcul du dataframe soit plus lent que l'acc√®s disque pour r√©cup√©rer les donn√©es.\n",
    "\n",
    "La r√©plication est int√©ressante si le recalcul du dataframe est extr√™mement lent et que l'on souhaite donner la possibilit√© √† Spark de reprendre les traitements en cours sur un autre executor, en cas de panne partielle.\n",
    "\n",
    "**Exercice**\n",
    "\n",
    "üë∑ Ci-dessous, apr√®s avoir vid√© le cache, v√©rifier dans Spark UI l'effet du stockage `NONE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007a2f7-57de-4821-b49a-b71e735c8167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cacheManager.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df3660-4c07-4792-a9ce-58392afcce04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"StorageLevel.NONE\") {\n",
    "  orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-02-28\"))).persist(StorageLevel.NONE).take(1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1aa43f-3f65-4194-80f1-668a0ebea587",
   "metadata": {},
   "source": [
    "üë∑ Ex√©cutez la cellule ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f354b439-d222-43ee-b628-6017b8c2d3ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "callWithName(\"StorageLevel.MEMORY_ONLY\") {\n",
    "  val memory_only =\n",
    "    orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-01\"))).persist(StorageLevel.MEMORY_ONLY).take(1).toList\n",
    "  println(s\"memory_only = $memory_only\")\n",
    "}\n",
    "callWithName(\"StorageLevel.MEMORY_ONLY_SER\") {\n",
    "  val memory_only_ser =\n",
    "    orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-02\"))).persist(StorageLevel.MEMORY_ONLY_SER).take(1).toList\n",
    "  println(s\"memory_only_ser = $memory_only_ser\")\n",
    "}\n",
    "callWithName(\"StorageLevel.DISK_ONLY\") {\n",
    "  val disk_only =\n",
    "    orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-03\"))).persist(StorageLevel.DISK_ONLY).take(1).toList\n",
    "  println(s\"disk_only = $disk_only\")\n",
    "}\n",
    "callWithName(\"StorageLevel.MEMORY_AND_DISK\") {\n",
    "  val memory_and_disk =\n",
    "    orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-04\"))).persist(StorageLevel.MEMORY_AND_DISK).take(1).toList\n",
    "  println(s\"memory_and_disk = $memory_and_disk\")\n",
    "}\n",
    "callWithName(\"StorageLevel.MEMORY_AND_DISK_SER\") {\n",
    "  val memory_and_disk_ser =\n",
    "    orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-05\"))).persist(StorageLevel.MEMORY_AND_DISK_SER).take(1).toList\n",
    "  println(s\"memory_and_disk_ser = $memory_and_disk_ser\")\n",
    "}\n",
    "// experimental\n",
    "callWithName(\"StorageLevel.OFF_HEAP\") {\n",
    "  val off_heap =\n",
    "    orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-06\"))).persist(StorageLevel.OFF_HEAP).take(1).toList\n",
    "  println(s\"off_heap = $off_heap\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277dfc38-0f5b-41ea-bded-5bb74d5f487c",
   "metadata": {},
   "source": [
    "ü§î **Question** ü§î\n",
    "\n",
    "V√©rifiez dans Spark UI la strat√©gie de stockage qui semble la meilleure. Appuyez-vous pour cela sur les statistiques de latence et de consommation d'espace.\n",
    "\n",
    "----\n",
    "\n",
    "Nous allons maintenant voir l'effet d'une strat√©gie de stockage impliquant une r√©plication, sachant que nous n'avons qu'un seul executor (ie. le driver).\n",
    "\n",
    "Apr√®s avoir vid√© le cache et lanc√© la requ√™te, regardez dans Spark UI, dans l'onglet _Storage_, si un espace de stockage a √©t√© cr√©√©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effc384-4b93-4322-88db-90e79c15ce0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cacheManager.clearCache()\n",
    "callWithName(\"StorageLevel.DISK_ONLY_2\") {\n",
    "  orders.where(to_date($\"timestamp\") === to_date(lit(\"2023-03-07\"))).persist(StorageLevel.DISK_ONLY_2).take(1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a8292a-0ec5-41f2-8dfb-b88cf0c6c8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.11"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
