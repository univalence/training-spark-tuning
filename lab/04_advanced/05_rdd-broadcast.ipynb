{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc79ce7-6e1e-4f18-87e5-0efcbe21f987",
   "metadata": {},
   "source": [
    "# Broadcast\n",
    "\n",
    "Nous allons voir ici un concept utiliser avec Spark Core et utilisé sous une autre forme avec Spark SQL. Il s'agit des variables _broadcast_.\n",
    "\n",
    "Nous sommes dans une situation où nous avons récupéré une dataset et nous voulons croiser ses données avec celle d'un référentiel. Par exemple, nous avons récupéré des données de commandes client. Sauf que dans le champ client, nous n'avons que des identifiants et pas l'identité du client. Cette relation entre identité et identifiant du client est fourni dans un autre fichier. On pourrait charger ce fichier dans un RDD, mais il est possible que ce fichier des identifiants soit suffisamment petit pour tenir en mémoire et qu'il peut s'avérer plus intéressant de copier ses données dans chaque exécuteur.\n",
    "\n",
    "C'est dans ce cas que les variables _broadcast_ peuvent être utilisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29244044-b8d6-495e-a9ea-520031795d56",
   "metadata": {},
   "source": [
    "## Prélude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee08235-a954-4b02-a2eb-f4c117e13750",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-core:3.4.1`\n",
    "import $ivy.`org.apache.spark::spark-sql:3.4.1`\n",
    "import $ivy.`org.slf4j:slf4j-reload4j:2.0.6`\n",
    "\n",
    "import org.apache.logging.log4j.Level\n",
    "import org.apache.logging.log4j.core.config.Configurator\n",
    "\n",
    "// Avoid disturbing logs\n",
    "Configurator.setRootLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c312b8-ae0b-424c-94d5-28a3acd85375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.rdd._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .master(\"local[*]\")\n",
    "    // L'appel ci-dessous sert à donner un nom à votre application\n",
    "    // Ce apparaîtra notamment dans la Spark UI\n",
    "    .appName(\"Spark tuning - broadcast\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "val sparkContext = spark.sparkContext\n",
    "\n",
    "// Ce script fournit que élément supplémentaires pour rendre l'affichage plus confortable\n",
    "import $file.^.internal.spark_helper\n",
    "import spark_helper.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c611e5-678f-463c-b79a-1f29d636cef8",
   "metadata": {},
   "source": [
    "## Chargement d'un fichier de mapping\n",
    "\n",
    "Dans le code ci-dessous, nous allons charger un fichier contenant des correspondances entre identifiant client et nom de client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7703c-0274-405e-b2d3-790aba82b23f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import scala.util.Using\n",
    "import scala.io.Source\n",
    "\n",
    "val mappingFilename = \"data/client-mapping.csv\"\n",
    "\n",
    "val mapping =\n",
    "    Using(Source.fromFile(mappingFilename)) { file =>\n",
    "      (\n",
    "        for (line <- file.getLines().drop(1)) yield {\n",
    "          val fields = line.split(\",\")\n",
    "          fields(0) -> fields(1)\n",
    "        }\n",
    "      ).toMap\n",
    "    }.get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43dead-71a8-498d-9822-bc90ac920655",
   "metadata": {},
   "source": [
    "## Chargement des commandes clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c3500-aef8-4964-a476-3d52e9d8bb39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%data limit=10,truncate=120\n",
    "\n",
    "val rawData: RDD[String] = sparkContext.textFile(\"data/orders.csv\", 4)\n",
    "\n",
    "val header: String    = rawData.first()\n",
    "val data: RDD[String] = rawData.filter(line => line != header)\n",
    "\n",
    "import java.time._\n",
    "import java.time.format._\n",
    "\n",
    "case class Order(\n",
    "  id:        String,\n",
    "  clientId:  String,\n",
    "  timestamp: LocalDateTime,\n",
    "  product:   String,\n",
    "  price:     Double\n",
    ")\n",
    "\n",
    "def toLocalDateTime(field: String): LocalDateTime =\n",
    "  LocalDateTime.parse(\n",
    "    field,\n",
    "    DateTimeFormatter.ISO_LOCAL_DATE_TIME\n",
    "  )\n",
    "\n",
    "def lineToOrder(line: String): Order = {\n",
    "  val fields = line.split(\",\")\n",
    "  Order(\n",
    "    id = fields(0),\n",
    "    clientId = fields(1),\n",
    "    timestamp = toLocalDateTime(fields(2)),\n",
    "    product = fields(3),\n",
    "    price = fields(4).toDouble,\n",
    "  )\n",
    "}\n",
    "\n",
    "val orders: RDD[Order] = data.map(lineToOrder)\n",
    "\n",
    "orders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022ac5ba-0c11-4665-95e5-4515a0f05d24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Broadcast\n",
    "\n",
    "Une variable _broadcast_ se crée à partir du SparkContext, en utilisant la méthode `.broadcast()` en passant en paramètre la valeur à diffuser sur les exécuteurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f9bee-7cea-4797-b9ef-e83161f42b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val broadcastMapping = ???"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5d08d-fd21-4eb8-b5a6-8d9c43d11df5",
   "metadata": {},
   "source": [
    "La récupération de la valeur associée à une variable _broadcast_ se fait en appelant la méthode `.value`.\n",
    "\n",
    "Comme notre table de correspondance `broadcastMapping` représente une collection de type `Map` et que nous souhaitons récupérer le nom d'un client par rapport à son identifiant (`order.clientId`), s'il est présent, nous allons utiliser la méthode `.getOrElse(key, default)` pour récupérer le nom du client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b41822-50a7-4095-bea0-cc6b880396b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val mappedOrders =\n",
    "  orders.map(order =>\n",
    "    order.copy(clientId = ???)\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84c92f3-b390-4005-9811-64deb17bcebf",
   "metadata": {
    "tags": []
   },
   "source": [
    "Nous obtenons maintenant cet affichage :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eb07c3-f12e-429e-aa60-3f6d78547cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%data limit=10,truncate=120\n",
    "\n",
    "mappedOrders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a42af5a-3d3f-45ce-be71-77e1c0eef062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
