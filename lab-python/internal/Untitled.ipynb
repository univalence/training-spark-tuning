{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805dbe88-e63f-47a5-8e5f-81ab504e694e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.logging.log4j.Level\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.logging.log4j.core.config.Configurator\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.apache.spark::spark-core:3.4.1`\n",
    "import $ivy.`org.apache.spark::spark-sql:3.4.1`\n",
    "import $ivy.`org.slf4j:slf4j-reload4j:2.0.6`\n",
    "\n",
    "import org.apache.logging.log4j.Level\n",
    "import org.apache.logging.log4j.core.config.Configurator\n",
    "\n",
    "// Avoid disturbing logs\n",
    "Configurator.setRootLevel(Level.OFF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d6bf1c-db18-48cc-86b4-a64475552064",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling /home/jovyan/work/internal/spark_helper.sc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Loading <code>spark-stubs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Getting spark JARs\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Creating SparkSession\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J providers.\n",
      "SLF4J: Found provider [org.apache.logging.slf4j.SLF4JServiceProvider@20bdb336]\n",
      "SLF4J: Found provider [org.slf4j.reload4j.Reload4jServiceProvider@1229439f]\n",
      "SLF4J: See https://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual provider is of type [org.apache.logging.slf4j.SLF4JServiceProvider@20bdb336]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a target=\"_blank\" href=\"http://0adca2debb39:4041\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.functions._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.rdd._\u001b[39m\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@47fa6658\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mspark_helper.implicits._\u001b[39m\n",
       "\u001b[36mres2_7\u001b[39m: \u001b[32mBoolean\u001b[39m = \u001b[32mtrue\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.rdd._\n",
    "\n",
    "val spark = {\n",
    "  NotebookSparkSession.builder()\n",
    "    .progress(enable = true, keep = true, useBars = false)\n",
    "    .master(\"local[*]\")\n",
    "    // L'appel ci-dessous sert à donner un nom à votre application\n",
    "    // Ce apparaîtra notamment dans la Spark UI\n",
    "    .appName(\"Sales Analysis - SparkSQL\")\n",
    "    .getOrCreate()\n",
    "}\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "// Ce script fournit que élément supplémentaires pour rendre l'affichage plus confortable\n",
    "import $file.^.internal.spark_helper\n",
    "import spark_helper.implicits._\n",
    "spark_helper.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40512a1c-d13b-40c2-b24c-8df92db2d63a",
   "metadata": {},
   "outputs": [
    {
     "ename": "java.lang.ArrayIndexOutOfBoundsException",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[31mjava.lang.ArrayIndexOutOfBoundsException: 1\u001b[39m",
      "  ammonite.$sess.spark_helper$Helper$TrainingExecuteHook$.$anonfun$hook$4(\u001b[32mspark_helper.sc\u001b[39m:\u001b[32m42\u001b[39m)",
      "  scala.collection.ArrayOps$.map$extension(\u001b[32mArrayOps.scala\u001b[39m:\u001b[32m934\u001b[39m)",
      "  ammonite.$sess.spark_helper$Helper$TrainingExecuteHook$.$anonfun$hook$3(\u001b[32mspark_helper.sc\u001b[39m:\u001b[32m40\u001b[39m)",
      "  scala.Option.map(\u001b[32mOption.scala\u001b[39m:\u001b[32m242\u001b[39m)",
      "  ammonite.$sess.spark_helper$Helper$TrainingExecuteHook$.hook(\u001b[32mspark_helper.sc\u001b[39m:\u001b[32m33\u001b[39m)",
      "  almond.Execute.$anonfun$apply$8(\u001b[32mExecute.scala\u001b[39m:\u001b[32m443\u001b[39m)",
      "  scala.util.Either.flatMap(\u001b[32mEither.scala\u001b[39m:\u001b[32m352\u001b[39m)",
      "  almond.Execute.$anonfun$apply$7(\u001b[32mExecute.scala\u001b[39m:\u001b[32m442\u001b[39m)",
      "  scala.util.Success.flatMap(\u001b[32mTry.scala\u001b[39m:\u001b[32m258\u001b[39m)",
      "  almond.Execute.$anonfun$apply$6(\u001b[32mExecute.scala\u001b[39m:\u001b[32m441\u001b[39m)",
      "  scala.collection.LinearSeqOps.foldLeft(\u001b[32mLinearSeq.scala\u001b[39m:\u001b[32m183\u001b[39m)",
      "  scala.collection.LinearSeqOps.foldLeft$(\u001b[32mLinearSeq.scala\u001b[39m:\u001b[32m179\u001b[39m)",
      "  scala.collection.immutable.List.foldLeft(\u001b[32mList.scala\u001b[39m:\u001b[32m79\u001b[39m)",
      "  almond.Execute.$anonfun$apply$5(\u001b[32mExecute.scala\u001b[39m:\u001b[32m440\u001b[39m)",
      "  almond.internals.CaptureImpl.$anonfun$apply$2(\u001b[32mCaptureImpl.scala\u001b[39m:\u001b[32m52\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  scala.Console$.withErr(\u001b[32mConsole.scala\u001b[39m:\u001b[32m193\u001b[39m)",
      "  almond.internals.CaptureImpl.$anonfun$apply$1(\u001b[32mCaptureImpl.scala\u001b[39m:\u001b[32m44\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  scala.Console$.withOut(\u001b[32mConsole.scala\u001b[39m:\u001b[32m164\u001b[39m)",
      "  almond.internals.CaptureImpl.apply(\u001b[32mCaptureImpl.scala\u001b[39m:\u001b[32m44\u001b[39m)",
      "  almond.Execute.capturingOutput(\u001b[32mExecute.scala\u001b[39m:\u001b[32m245\u001b[39m)",
      "  almond.Execute.$anonfun$apply$4(\u001b[32mExecute.scala\u001b[39m:\u001b[32m439\u001b[39m)",
      "  almond.Execute.$anonfun$withClientStdin$1(\u001b[32mExecute.scala\u001b[39m:\u001b[32m224\u001b[39m)",
      "  scala.util.DynamicVariable.withValue(\u001b[32mDynamicVariable.scala\u001b[39m:\u001b[32m59\u001b[39m)",
      "  scala.Console$.withIn(\u001b[32mConsole.scala\u001b[39m:\u001b[32m227\u001b[39m)",
      "  almond.Execute.withClientStdin(\u001b[32mExecute.scala\u001b[39m:\u001b[32m220\u001b[39m)",
      "  almond.Execute.$anonfun$apply$3(\u001b[32mExecute.scala\u001b[39m:\u001b[32m436\u001b[39m)",
      "  almond.Execute.withInputManager(\u001b[32mExecute.scala\u001b[39m:\u001b[32m210\u001b[39m)",
      "  almond.Execute.$anonfun$apply$2(\u001b[32mExecute.scala\u001b[39m:\u001b[32m435\u001b[39m)",
      "  ammonite.repl.Signaller.apply(\u001b[32mSignaller.scala\u001b[39m:\u001b[32m28\u001b[39m)",
      "  almond.Execute.interruptible(\u001b[32mExecute.scala\u001b[39m:\u001b[32m271\u001b[39m)",
      "  almond.Execute.$anonfun$apply$1(\u001b[32mExecute.scala\u001b[39m:\u001b[32m434\u001b[39m)",
      "  almond.Execute.withOutputHandler(\u001b[32mExecute.scala\u001b[39m:\u001b[32m236\u001b[39m)",
      "  almond.Execute.apply(\u001b[32mExecute.scala\u001b[39m:\u001b[32m433\u001b[39m)",
      "  almond.ScalaInterpreter.execute(\u001b[32mScalaInterpreter.scala\u001b[39m:\u001b[32m180\u001b[39m)",
      "  almond.interpreter.InterpreterToIOInterpreter.$anonfun$execute$2(\u001b[32mInterpreterToIOInterpreter.scala\u001b[39m:\u001b[32m66\u001b[39m)",
      "  cats.effect.IOFiber.runLoop(\u001b[32mIOFiber.scala\u001b[39m:\u001b[32m255\u001b[39m)",
      "  cats.effect.IOFiber.autoCedeR(\u001b[32mIOFiber.scala\u001b[39m:\u001b[32m1413\u001b[39m)",
      "  cats.effect.IOFiber.run(\u001b[32mIOFiber.scala\u001b[39m:\u001b[32m119\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor.runWorker(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m1149\u001b[39m)",
      "  java.util.concurrent.ThreadPoolExecutor$Worker.run(\u001b[32mThreadPoolExecutor.java\u001b[39m:\u001b[32m624\u001b[39m)",
      "  java.lang.Thread.run(\u001b[32mThread.java\u001b[39m:\u001b[32m750\u001b[39m)"
     ]
    }
   ],
   "source": [
    "// import $file.^.internal.spark_helper\n",
    "// import spark_helper.implicits._\n",
    "// spark_helper.init()\n",
    "1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "612cd135-54d8-410a-80eb-eb6957fd70ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><code>csv</code> at <code>cell10.sc:3</code> (done)</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><code>showHTML</code> (done)</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<table class=\"table\">\n",
       "  <tr>\n",
       "    <th>station_name</th><th>station_rating</th><th>station_review_count</th><th>city</th><th>postal_code</th><th>county</th><th>departement</th><th>region</th><th>latitude</th><th>longitude</th>\n",
       "  </tr>\n",
       "  <tr><td>Lus la ...</td><td>5.0</td><td>1</td><td>Lus-la-...</td><td>26620</td><td>Die</td><td>Drôme</td><td>Auvergn...</td><td>44.679971</td><td>5.7661523</td></tr><tr><td>Val d'I...</td><td>4.4</td><td>125</td><td>Val-d'I...</td><td>73150</td><td>Albertv...</td><td>Savoie</td><td>Auvergn...</td><td>45.4498666</td><td>6.9804421</td></tr><tr><td>La Grave</td><td>4.4</td><td>69</td><td>La Grave</td><td>05320</td><td>Briançon</td><td>Hautes-...</td><td>Provenc...</td><td>45.0455379</td><td>6.3068184</td></tr><tr><td>Le granier</td><td>4.4</td><td>8</td><td>Aime-la...</td><td>73210</td><td>Albertv...</td><td>Savoie</td><td>Auvergn...</td><td>45.6008...</td><td>6.62550...</td></tr><tr><td>Mont-Sa...</td><td>4.4</td><td>7</td><td>Mont-Sa...</td><td>74130</td><td>Bonneville</td><td>Haute-S...</td><td>Auvergn...</td><td>46.0508713</td><td>6.4792764</td></tr>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdata\u001b[39m: \u001b[32mDataFrame\u001b[39m = [station_name: string, station_rating: string ... 8 more fields]\n",
       "\u001b[36mresult\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mRow\u001b[39m] = [station_name: string, station_rating: string ... 8 more fields]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%data limit=5,truncate=10\n",
    "\n",
    "val data = (spark.read.option(\"header\", true)\n",
    "                   .csv(\"stations.csv\"))\n",
    "val result = (data\n",
    "    .select(\"*\")\n",
    "    .where(data(\"station_rating\") >= 4.0))\n",
    "    .where(data(\"city\").isNotNull)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1734a67e-ef49-4996-94be-1a5e6ec34409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter (station_rating#151 >= 4.0)\n",
      "+- Project [station_name#150, station_rating#151, station_review_count#152, city#153, postal_code#154, county#155, departement#156, region#157, latitude#158, longitude#159]\n",
      "   +- Relation [station_name#150,station_rating#151,station_review_count#152,city#153,postal_code#154,county#155,departement#156,region#157,latitude#158,longitude#159] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "station_name: string, station_rating: string, station_review_count: string, city: string, postal_code: string, county: string, departement: string, region: string, latitude: string, longitude: string\n",
      "Filter (cast(station_rating#151 as double) >= 4.0)\n",
      "+- Project [station_name#150, station_rating#151, station_review_count#152, city#153, postal_code#154, county#155, departement#156, region#157, latitude#158, longitude#159]\n",
      "   +- Relation [station_name#150,station_rating#151,station_review_count#152,city#153,postal_code#154,county#155,departement#156,region#157,latitude#158,longitude#159] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Filter (isnotnull(station_rating#151) AND (cast(station_rating#151 as double) >= 4.0))\n",
      "+- Relation [station_name#150,station_rating#151,station_review_count#152,city#153,postal_code#154,county#155,departement#156,region#157,latitude#158,longitude#159] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Filter (isnotnull(station_rating#151) AND (cast(station_rating#151 as double) >= 4.0))\n",
      "+- FileScan csv [station_name#150,station_rating#151,station_review_count#152,city#153,postal_code#154,county#155,departement#156,region#157,latitude#158,longitude#159] Batched: false, DataFilters: [isnotnull(station_rating#151), (cast(station_rating#151 as double) >= 4.0)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/home/jovyan/work/internal/stations.csv], PartitionFilters: [], PushedFilters: [IsNotNull(station_rating)], ReadSchema: struct<station_name:string,station_rating:string,station_review_count:string,city:string,postal_c...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.explain(extended=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94f08a-4874-467d-8c9c-3c39987389e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.13",
   "language": "scala",
   "name": "scala213"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".sc",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
